---
title: "I Talk to Claude More Than Humans (And What That Taught Me)"
description: "Three weeks using Claude as a coding agent revealed the reality behind AI hype: pattern-following, the 95% ceiling, and confident hallucinations. February 2026."
date: 2026-02-07
published: true
tags: ["AI", "coding agents", "Claude", "LLM", "development", "machine learning"]
author: "Paras Sharma"
---

In the last three weeks, I've sent more messages to Claude than to any human being. Not the chatbot. The coding agent.

With everyone hyping up AI agents replacing developers, I wanted to see what actually happens when you use one full-time. Real work, not demos.

It's February 2026. Things might change in the coming months. But this is how it feels right now.

## They Follow Patterns, They Don't Learn

Use these coding agents every day and you'll see it: they do the same thing over and over.

Give it context, write better prompts, share your codebase. Doesn't matter. It follows the same patterns. It's not learning your project. It's guessing what code comes next based on patterns from training.

At first that feels amazing. Then it feels like working with someone who memorized Stack Overflow but doesn't understand why anything works.

## The 95% Problem

So you compensate. Build systems. Write specs. Teach it your patterns.

You get to 95%. Maybe 99% on a good day. But that last 1%? That's where the actual work is. And nothing gets you past it.

The edge cases. The parts needing real understanding, not pattern matching. The ceiling doesn't move.

## They Lie (Confidently)

Worst part: they lie about code.

They tell you it compiles when it doesn't. Import libraries that don't exist. Call functions wrong. Present guesses as working solutions.

And they sound so sure that you start trusting them. You stop checking. Then you're debugging code that was broken from the start.

You have to verify everything. Every line. That's not extra work. That's the whole job now.

## This Isn't Getting Fixed

These aren't bugs. Hallucinations, patterns, the 99% limit - that's how these things work. They're predictive, not intelligent.

Useful for boilerplate and scaffolding? Sure. But they're tools, not teammates. They need constant supervision.

Anthropic can call it "agentic coding" all they want. What it actually is: very fast autocomplete that needs you to check its work.
